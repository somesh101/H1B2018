CREATE TABLE h1b_applications(s_no int,case_status string, employer_name string, soc_name string, job_title string, full_time_position string,prevailing_wage bigint,year string, worksite string, longitute double, latitute double )
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
"separatorChar" = ",",
"quoteChar" = "\""
) STORED AS TEXTFILE;

load data local inpath '/home/hduser/h1b.csv' overwrite into table h1b_applications;

CREATE TABLE h1b_app2(s_no int,case_status string, employer_name string, soc_name string, job_title string, full_time_position string,prevailing_wage bigint,year string, worksite string, longitute double, latitute double )
row format delimited
fields terminated by '\t'
STORED AS TEXTFILE;


INSERT OVERWRITE TABLE h1b_app2 SELECT regexp_replace(s_no, "\t", ""), regexp_replace(case_status, "\t", ""), regexp_replace(employer_name, "\t", ""), regexp_replace(soc_name, "\t", ""), regexp_replace(job_title, "\t", ""), regexp_replace(full_time_position, "\t", ""), prevailing_wage, regexp_replace(year, "\t", ""), regexp_replace(worksite, "\t", ""), regexp_replace(longitute, "\t", ""), regexp_replace(latitute, "\t", "") FROM h1b_applications where case_status != "NA";

CREATE TABLE h1b_final(s_no int,case_status string, employer_name string, soc_name string, job_title string, full_time_position string,prevailing_wage bigint,year string, worksite string, longitute double, latitute double )
row format delimited
fields terminated by '\t'
STORED AS TEXTFILE;

INSERT OVERWRITE TABLE h1b_final SELECT s_no,
case when trim(case_status) = "PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED" then "DENIED"
when trim(case_status) = "REJECTED" then "DENIED"
when trim(case_status) = "INVALIDATED" then "DENIED"
else case_status end, 
employer_name, soc_name, job_title, full_time_position,
case when prevailing_wage is null then 100000
else prevailing_wage end,
year, worksite, longitute, latitute 
FROM h1b_app2;


select year, count(*) from h1b_final group by year;
--------------------------------------------------
2011	358767
2013	442114
2015	618727
2012	415607
2014	519427
2016	647803

total 3002445 records

select case_status, count(*) from h1b_final group by case_status;
----------------------------------------------------------------

new data
-------
CERTIFIED-WITHDRAWN	202659
WITHDRAWN	89799
CERTIFIED	2615623
DENIED	94364

total records : 3002445




for year 2013
-------------
CERTIFIED-WITHDRAWN	35432
WITHDRAWN	11590
CERTIFIED	382951
DENIED	12141
------------------------------
total - 442114
------------------------------ 

old data
--------
CERTIFIED-WITHDRAWN	202659
PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED	15
REJECTED	2
WITHDRAWN	89799
CERTIFIED	2615623
DENIED	94346
INVALIDATED	1


and there is no NULL values
and there are no NA values also


select case_status, count(*) from h1b_final group by case_status;















--regexp_replace(job_title, "\t", "")

--select * from h1b_app2 where locate('\t', job_title) != 0 ;
--select * from h1b_app2 where s_no = 129170;
--select * from h1b_app2 where case_status = "NA";


--total number of records : 3002445 - 7 = 3002438 records


select year, count(*) from tbl group by year;




--load the data in pig
----------------------

app = load '/user/hive/warehouse/h1b_final' using PigStorage() as (s_no:int, case_status:chararray, employer_name:chararray, soc_name:chararray, job_title:chararray, full_time_position:chararray,prevailing_wage:int,year:chararray, worksite:chararray, longitute:double, latitute:double);

filtered_app = limit app 10;

dump filtered_app;


load ur data from map reduce output into pig
order it
store it






